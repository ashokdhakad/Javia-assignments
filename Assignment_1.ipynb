{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashokdhakad/Javia-assignments/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:21:20.523958Z",
          "start_time": "2020-12-04T12:21:15.255095Z"
        },
        "id": "-j_XeDHse0Ty"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!python -m pip install jovian --upgrade -q\n",
        "import jovian\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn3WKmWMe0T0"
      },
      "source": [
        "# PyTorch functions for operations on tensors\n",
        "\n",
        "An short introduction about PyTorch and about the chosen functions. \n",
        "\n",
        "- torch.from_numpy\n",
        "- torch.complex\n",
        "- torch.hstack\n",
        "- tensor.narrow\n",
        "- torch.transpose\n",
        "\n",
        "Before we begin, let's install and import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:31:50.989577Z",
          "start_time": "2020-12-04T12:26:25.033893Z"
        },
        "id": "YBso8JB7e0T0",
        "outputId": "213409ff-084e-4424-89fc-29629d1b9fd4"
      },
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "!pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.16.4)\n",
            "Collecting torch==1.7.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.7.0%2Bcpu-cp37-cp37m-win_amd64.whl (184.2 MB)\n",
            "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.7.0+cpu) (3.7.4.3)\n",
            "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.7.0+cpu) (0.17.1)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.16.4)\n",
            "Collecting torchaudio==0.7.0\n",
            "  Downloading https://download.pytorch.org/whl/torchaudio-0.7.0-cp37-none-win_amd64.whl (103 kB)\n",
            "Collecting torchvision==0.8.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.8.1%2Bcpu-cp37-cp37m-win_amd64.whl (808 kB)\n",
            "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\abc\\appdata\\roaming\\python\\python37\\site-packages (from torchvision==0.8.1+cpu) (5.1.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.16.4)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: dataclasses, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 0.4.1\n",
            "    Uninstalling torch-0.4.1:\n",
            "      Successfully uninstalled torch-0.4.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.1.6\n",
            "    Uninstalling torchvision-0.1.6:\n",
            "      Successfully uninstalled torchvision-0.1.6\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0+cpu torchaudio-0.7.0 torchvision-0.8.1+cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:32:43.970799Z",
          "start_time": "2020-12-04T12:32:42.299214Z"
        },
        "id": "ifWJ6Fhue0T0"
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:32:46.306007Z",
          "start_time": "2020-12-04T12:32:46.302006Z"
        },
        "id": "hCdQ7bwigNzw"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRGJYHzxe0T1"
      },
      "source": [
        "\n",
        "\n",
        "# This is formatted as code\n",
        "\n",
        "## Function 1 - torch.from_numpy\n",
        "\n",
        "Creates a Tensor from a numpy.ndarray. The returned tensor and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. The returned tensor is not resizable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:32:50.055817Z",
          "start_time": "2020-12-04T12:32:50.042825Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl8j0Az9e0T1",
        "outputId": "aefb96eb-0c19-4106-a832-7e2dbe8da895"
      },
      "source": [
        "# Example 1 - working \n",
        "arr = np.array([[1,2,3],[5,6,7]])\n",
        "\n",
        "ten = torch.from_numpy(arr)\n",
        "print(ten)\n",
        "print(ten.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [5, 6, 7]], dtype=torch.int32)\n",
            "torch.int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A4gxUC2e0T4"
      },
      "source": [
        "The above example shows how a 2D numpy array has been converted to tensor of int64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:32:53.185987Z",
          "start_time": "2020-12-04T12:32:53.074952Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdFEN8NDe0T4",
        "outputId": "b459be66-b6c8-42ae-e7ea-7f8327a6b11a"
      },
      "source": [
        "# Example 2 - working\n",
        "arr1 = np.random.randn(5,5)\n",
        "print(arr1)\n",
        "print(arr1.dtype)\n",
        "\n",
        "t1 = torch.from_numpy(arr1)\n",
        "print(t1)\n",
        "print(t1.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.66540852 -0.92414309  0.08709296 -1.37452946  0.50760422]\n",
            " [ 1.00351854 -2.4704621  -0.69684151 -0.17373582  0.9264806 ]\n",
            " [-0.83696218  1.51966587 -0.61574608  0.18435946 -0.09853379]\n",
            " [-0.54145383 -0.44714845 -0.91810112 -0.5901262  -0.62310574]\n",
            " [ 0.97356119  1.3755779  -0.02834572  0.85799214  0.44058152]]\n",
            "float64\n",
            "tensor([[-0.6654, -0.9241,  0.0871, -1.3745,  0.5076],\n",
            "        [ 1.0035, -2.4705, -0.6968, -0.1737,  0.9265],\n",
            "        [-0.8370,  1.5197, -0.6157,  0.1844, -0.0985],\n",
            "        [-0.5415, -0.4471, -0.9181, -0.5901, -0.6231],\n",
            "        [ 0.9736,  1.3756, -0.0283,  0.8580,  0.4406]], dtype=torch.float64)\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiOlr-mBe0T4"
      },
      "source": [
        "Example 2 shows how numpy array of shape 5x5 is transformed into tensor of same float64 data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:32:56.857149Z",
          "start_time": "2020-12-04T12:32:56.688253Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "MQ_KCbMce0T4",
        "outputId": "066d4255-249d-4171-f7ca-a288ab79c738"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "arr2 = np.array([[1,2,3],['a','b','c']])\n",
        "print(arr2.dtype)\n",
        "\n",
        "t3 = torch.from_numpy(arr2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<U11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-17-f41523f83c7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mt3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjQEfXjHe0T5"
      },
      "source": [
        "The array, arr2 has datatypes strings in one of the sub arrays. This is not supported by the tensors. As mentioned in the error, the only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls7XnhXoe0T5"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "\n",
        "You could use the from_numpy function when you want to convert an numpy array into a tensor, given you respect the tensor restrictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcRCjTR9e0T5"
      },
      "source": [
        "Let's save our work using Jovian before continuing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:33:07.363574Z",
          "start_time": "2020-12-04T12:33:00.238886Z"
        },
        "id": "o7drLiipe0T5",
        "outputId": "c1fce960-2fbe-4fdb-dbb4-3f8a94984126"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:33:14.515037Z",
          "start_time": "2020-12-04T12:33:14.510044Z"
        },
        "id": "yPThyeK7e0T5"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:34:23.148379Z",
          "start_time": "2020-12-04T12:33:30.435731Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ogm0QYvfe0T5",
        "outputId": "d223da67-935e-4c2e-e70b-cfbe80b81281"
      },
      "source": [
        "jovian.commit(project='Assignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\n",
            "API KEY: ········\n",
            "[jovian] Creating a new project \"ashokdhakad/Assignment-1\"\n",
            "[jovian] Uploading notebook..\n",
            "[jovian] Capturing environment..\n",
            "[jovian] Committed successfully! https://jovian.ai/ashokdhakad/assignment-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/ashokdhakad/assignment-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K4PhZrue0T5"
      },
      "source": [
        "## Function 2 - torch.complex\n",
        "\n",
        "Constructs a complex tensor with its real part equal to real and it's imaginary part equal to imag. Takes two tensors as input and outs one complex tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:36:50.462147Z",
          "start_time": "2020-12-04T12:36:50.446154Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27OTito7e0T6",
        "outputId": "74ec1b6d-c720-461f-9740-9bf906e6aaef"
      },
      "source": [
        "# Example 1 - working\n",
        "real = torch.tensor([1,2], dtype = torch.float32)\n",
        "imag = torch.tensor([3,4], dtype=torch.float32)\n",
        "\n",
        "z = torch.complex(real,imag)\n",
        "print(z.dtype)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.complex64\n",
            "tensor([1.+3.j, 2.+4.j])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3czKoaVe0T6"
      },
      "source": [
        "The above example shows how to contruct a complex tensor by joining a real and imaginaroy part of tensors.\n",
        "Note that, when real and imag are of data type float32 the output has a complex of datatype complex64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:36:54.327012Z",
          "start_time": "2020-12-04T12:36:54.311021Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omN7jvIRe0T6",
        "outputId": "bb76f349-38b5-400b-d052-582ad720c37f"
      },
      "source": [
        "# Example 2 - working\n",
        "real = torch.tensor([[1,2,3],[7,8,9]], dtype = torch.float64)\n",
        "imag = torch.tensor([[11,12,13],[87,89,7878]], dtype = torch.float64)\n",
        "\n",
        "z = torch.complex(real, imag)\n",
        "print(z)\n",
        "print(z.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.+11.j, 2.+12.j, 3.+13.j],\n",
            "        [7.+87.j, 8.+89.j, 9.+7878.j]], dtype=torch.complex128)\n",
            "torch.complex128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT_LR7Cme0T6"
      },
      "source": [
        "The above example shows that complex accepts real and imag with same dtype. Also now that the dtype are of float64, the output complex has a datatype of complex128.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:36:58.080186Z",
          "start_time": "2020-12-04T12:36:57.474110Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "3FzMS0Rie0T6",
        "outputId": "3c89b43b-79ad-4457-d672-d5e37da4f2c4"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "real = torch.tensor([[1,2,3],[7,8,9]], dtype = torch.int64)\n",
        "imag = torch.tensor([[11,12,13],[87,89,7878]], dtype = torch.int64)\n",
        "\n",
        "z = torch.complex(real, imag)\n",
        "print(z)\n",
        "print(z.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected both inputs to be Float or Double tensors but got Long and Long",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-23-b8c473458b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m87\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m89\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7878\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected both inputs to be Float or Double tensors but got Long and Long"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMzhZNdme0T6"
      },
      "source": [
        "The torch.complex function only accepts real and imag tensors with datatypes of float or double and both of them should have similar datatypes for it to function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSgh056oe0T6"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "\n",
        "torch.complex function is really useful in building complex equation real quick. Just keep in mind the limitations of this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:37:42.358162Z",
          "start_time": "2020-12-04T12:37:26.110634Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "sYmJJzpPe0T6",
        "outputId": "6b7ac189-95cc-4d8b-e704-6dc73e5e3afa"
      },
      "source": [
        "jovian.commit(project='Assignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\n",
            "[jovian] Updating notebook \"ashokdhakad/assignment-1\" on https://jovian.ai/\n",
            "[jovian] Uploading notebook..\n",
            "[jovian] Capturing environment..\n",
            "[jovian] Committed successfully! https://jovian.ai/ashokdhakad/assignment-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/ashokdhakad/assignment-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abeXUux5e0T6"
      },
      "source": [
        "## Function 3 - torch.hstack\n",
        "\n",
        "The above function helps stack tensors in sequence horizontally (column wise). Takes multiple tensors as input and returns one concatanated tensor as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:37:49.688712Z",
          "start_time": "2020-12-04T12:37:49.668724Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njTYQccpe0T6",
        "outputId": "e55aa686-034a-4c46-852e-31a07dca85bc"
      },
      "source": [
        "# Example 1 - working\n",
        "t1 = torch.tensor([1, 2, 3, 5, 6])\n",
        "print(t1.dtype, end='\\n\\n')\n",
        "t2 = torch.tensor([4, 5, 6, 7, 8])\n",
        "print(t2.dtype, end='\\n\\n')\n",
        "\n",
        "t3 = torch.hstack((t1,t2))\n",
        "print(t3)\n",
        "print(t3.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "\n",
            "torch.int64\n",
            "\n",
            "tensor([1, 2, 3, 5, 6, 4, 5, 6, 7, 8])\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFXQn_FQe0T7"
      },
      "source": [
        "Explanation about example1:\n",
        "- t3 is a result of horizontal contactination of two tensors t1 & t2. The datatype remained same as t1 & t2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:37:53.432709Z",
          "start_time": "2020-12-04T12:37:53.405726Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RohfZuv7e0T7",
        "outputId": "2800a23c-6085-4606-f2e1-0d20199c519e"
      },
      "source": [
        "# Example 2 - working\n",
        "t1 = torch.tensor([[1.5],[2.5],[3.5]])\n",
        "print(t1.dtype, t1.shape, end='\\n\\n')\n",
        "t2 = torch.tensor([[4],[5],[6]])\n",
        "print(t2.dtype, t2.shape, end='\\n\\n')\n",
        "t3 = torch.hstack((t1,t2))\n",
        "print(t3)\n",
        "print(t3.dtype, t3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32 torch.Size([3, 1])\n",
            "\n",
            "torch.int64 torch.Size([3, 1])\n",
            "\n",
            "tensor([[1.5000, 4.0000],\n",
            "        [2.5000, 5.0000],\n",
            "        [3.5000, 6.0000]])\n",
            "torch.float32 torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb2NwSqGe0T7"
      },
      "source": [
        "Explanation about example:\n",
        "- This example has two tensors with same size of [3,1] but with different datatypes of float32 and int64, the resultant tensor has a datatype of float32 as the entire tensor has been converted into suitable, one datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:37:56.510258Z",
          "start_time": "2020-12-04T12:37:56.481273Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "X0XqDfzXe0T7",
        "outputId": "af57ef8f-6c8c-485c-dddb-fc8bfaf33dc1"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "\n",
        "t1 = torch.tensor([[1.5],[2.5],[3.5]])\n",
        "print(t1.dtype, t1.shape, end='\\n\\n')\n",
        "t2 = torch.tensor([[4],[5]])\n",
        "print(t2.dtype, t2.shape, end='\\n\\n')\n",
        "t3 = torch.hstack((t1,t2))\n",
        "print(t3)\n",
        "print(t3.dtype, t3.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32 torch.Size([3, 1])\n",
            "\n",
            "torch.int64 torch.Size([2, 1])\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Got 3 and 2 in dimension 0 (The offending index is 1)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-28-3a9f5f072f34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mt3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 3 and 2 in dimension 0 (The offending index is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fij6IZ_Qe0T7"
      },
      "source": [
        "Explanation about example:\n",
        "- passing tensors with different dimensions to the hstack function breaks it.\n",
        "- As the error suggests, sizes of tensors must match for it to work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJu0CnNke0T7"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "- tensor.hstack function comes in handy when you want to join multiple tensors, just be cautious about their datatypes and shape. Remember to pass in tensors of same dtype as arguements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:38:34.836283Z",
          "start_time": "2020-12-04T12:38:18.066942Z"
        },
        "id": "D7vC4k7ke0T7",
        "outputId": "e0d06c0f-cafd-451a-ce78-c7231bef4ea5"
      },
      "source": [
        "jovian.commit(project='Assignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\n",
            "[jovian] Updating notebook \"ashokdhakad/assignment-1\" on https://jovian.ai/\n",
            "[jovian] Uploading notebook..\n",
            "[jovian] Capturing environment..\n",
            "[jovian] Committed successfully! https://jovian.ai/ashokdhakad/assignment-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/ashokdhakad/assignment-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj_zubmle0T8"
      },
      "source": [
        "## Function 4 - tensor.narrow\n",
        "\n",
        "This function returns a new tensor that is a narrowed version of input tensor. Takes multiple arguments such as input, dim, start, length. The returned tensor and the input tensor share the same memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:38:52.735958Z",
          "start_time": "2020-12-04T12:38:52.722968Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBRUUsTqe0T8",
        "outputId": "80f51658-b23c-464d-bc47-887f18bb77db"
      },
      "source": [
        "# Example 1 - working\n",
        "t4 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(t4)\n",
        "\n",
        "nar_0 = torch.narrow(t4, 0, 1, 2)\n",
        "print(nar_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([[4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHeBAeC_e0T8"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function extracts a subset of the tensor t4 by starting at index 1, dimention 0 (specifies rows) and the length of 2 which grabs 2 rows out of 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:38:55.714309Z",
          "start_time": "2020-12-04T12:38:55.704297Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6HwWoLbe0T8",
        "outputId": "6c32521e-d164-4ce1-a0e4-90712f237d35"
      },
      "source": [
        "# Example 2 - working\n",
        "print(t4)\n",
        "\n",
        "nar_1 = torch.narrow(t4, 1, 0, 2)\n",
        "print(nar_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([[1, 2],\n",
            "        [4, 5],\n",
            "        [7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG7k9YHSe0T8"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function has been sliced vertically when you pass a dimention 1, it is starting at 0 index for columns and grabs 2 of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:38:58.331643Z",
          "start_time": "2020-12-04T12:38:58.308672Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "6bhKzjXae0T8",
        "outputId": "0e1b3413-249c-4fcd-a575-f40b4a8103e3"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "print(t4)\n",
        "\n",
        "nar_1 = torch.narrow(t4, 1, 0, 4)\n",
        "print(nar_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "start (0) + length (4) exceeds dimension size (3).",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-32-c770c218a869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnar_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnar_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: start (0) + length (4) exceeds dimension size (3)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrSvKGqbe0T8"
      },
      "source": [
        "Explanation about example:\n",
        " - touch.narrow function breaks when you pass the dimension greater than the dimension of the input tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXdNN9nYe0T8"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "- touch.narrow function is helpful in subsetting tensors and having multiple inputs makes it easier to mention the shape and size of the subset tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:39:31.400087Z",
          "start_time": "2020-12-04T12:39:13.188767Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "MZI_s9QXe0T8",
        "outputId": "ecd03952-cabd-425b-9a2f-779d327a2fcb"
      },
      "source": [
        "jovian.commit(project='Assignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\n",
            "[jovian] Updating notebook \"ashokdhakad/assignment-1\" on https://jovian.ai/\n",
            "[jovian] Uploading notebook..\n",
            "[jovian] Capturing environment..\n",
            "[jovian] Committed successfully! https://jovian.ai/ashokdhakad/assignment-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/ashokdhakad/assignment-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeZ1PHTve0T9"
      },
      "source": [
        "## Function 5 - torch.transpose\n",
        "\n",
        "The above function returns a tensor that is a transposed version of input. This function accpets parameters as input, dim0, and dim1. The given dimensions dim0 & dim1 are swapped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:39:40.289333Z",
          "start_time": "2020-12-04T12:39:40.274342Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr-ZSCRae0T9",
        "outputId": "804ea63e-035a-4e7d-cbf8-b14707c24e01"
      },
      "source": [
        "# Example 1 - working\n",
        "tt1 = torch.randn(5,3)\n",
        "print(tt1)\n",
        "\n",
        "tran1 = torch.transpose(tt1, 0, 1)\n",
        "print(tran1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-6.4652e-01,  1.2283e+00, -6.5223e-01],\n",
            "        [ 8.8932e-01, -5.2511e-04, -1.4620e+00],\n",
            "        [-1.4532e+00, -2.1534e+00,  5.2240e-01],\n",
            "        [-2.4678e-02, -5.2924e-01, -1.6293e-01],\n",
            "        [ 2.3136e+00,  8.8220e-01,  2.0149e+00]])\n",
            "tensor([[-6.4652e-01,  8.8932e-01, -1.4532e+00, -2.4678e-02,  2.3136e+00],\n",
            "        [ 1.2283e+00, -5.2511e-04, -2.1534e+00, -5.2924e-01,  8.8220e-01],\n",
            "        [-6.5223e-01, -1.4620e+00,  5.2240e-01, -1.6293e-01,  2.0149e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4ceUGLPe0T9"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function transposed the tensor of size [5,3] to a tensor of size [3,5]. 0, 1 in the above example denotes that they'd be transposed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:39:42.968547Z",
          "start_time": "2020-12-04T12:39:42.954555Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPir6Vx1e0T9",
        "outputId": "05340cef-362f-4362-969c-b559a00c1395"
      },
      "source": [
        "# Example 2 - working\n",
        "print(tt1)\n",
        "\n",
        "tran2 = torch.transpose(tt1, 1, 0)\n",
        "print(tran2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-6.4652e-01,  1.2283e+00, -6.5223e-01],\n",
            "        [ 8.8932e-01, -5.2511e-04, -1.4620e+00],\n",
            "        [-1.4532e+00, -2.1534e+00,  5.2240e-01],\n",
            "        [-2.4678e-02, -5.2924e-01, -1.6293e-01],\n",
            "        [ 2.3136e+00,  8.8220e-01,  2.0149e+00]])\n",
            "tensor([[-6.4652e-01,  8.8932e-01, -1.4532e+00, -2.4678e-02,  2.3136e+00],\n",
            "        [ 1.2283e+00, -5.2511e-04, -2.1534e+00, -5.2924e-01,  8.8220e-01],\n",
            "        [-6.5223e-01, -1.4620e+00,  5.2240e-01, -1.6293e-01,  2.0149e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrlWtRG-e0T9"
      },
      "source": [
        "Explanation about example:\n",
        "- The above function transposed the tensor of size [5,3] to a tensor of size [3,5]. 1,0  in the above example denotes that they'd be transposed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:39:45.797649Z",
          "start_time": "2020-12-04T12:39:45.781642Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "-zPJ4fnJe0T9",
        "outputId": "2dfa3da3-bbc2-48a1-d71f-3f9b98658c81"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "tran2 = torch.transpose(tt1,1, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-36-dd450531e105>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtran2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu4WTEG3e0T9"
      },
      "source": [
        "Explanation about example:\n",
        " - Dimensions for the transpose were out of range. Expecting to get the 0,1 or 1,2 but got different numbers which were out of range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiiBFA0Ze0T9"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        " - transpose function is very helpful when you want to do matrix multiplication of tensors with same shape( matrix multiplication is not possible on matrices with same shape), hence the transpose of them is required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:40:18.782554Z",
          "start_time": "2020-12-04T12:40:01.653140Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "95IXlEBpe0T9",
        "outputId": "dbb4c85b-c65f-4a25-b400-ee50489e3d21"
      },
      "source": [
        "jovian.commit(project='Assignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\n",
            "[jovian] Updating notebook \"ashokdhakad/assignment-1\" on https://jovian.ai/\n",
            "[jovian] Uploading notebook..\n",
            "[jovian] Capturing environment..\n",
            "[jovian] Committed successfully! https://jovian.ai/ashokdhakad/assignment-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/ashokdhakad/assignment-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDEZtQLfe0T-"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "The functions discussed are one of the important ones while doing tensor operations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tiu7Mzf5e0T-"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:40:57.120903Z",
          "start_time": "2020-12-04T12:40:37.454141Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "vomGFlM6e0T-",
        "outputId": "3dabd404-2068-4247-a7b0-7574b5b57e31"
      },
      "source": [
        "jovian.commit(project='Assignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\n",
            "[jovian] Updating notebook \"ashokdhakad/assignment-1\" on https://jovian.ai/\n",
            "[jovian] Uploading notebook..\n",
            "[jovian] Capturing environment..\n",
            "[jovian] Committed successfully! https://jovian.ai/ashokdhakad/assignment-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/ashokdhakad/assignment-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-04T12:41:20.967623Z",
          "start_time": "2020-12-04T12:41:05.590127Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "440forgCe0T-",
        "outputId": "1f36d646-ef8b-4547-80ea-0d36a0d5e5fc"
      },
      "source": [
        "jovian.submit(project='Assignment-1',assignment=\"zerotogans-a1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\n",
            "[jovian] Updating notebook \"ashokdhakad/assignment-1\" on https://jovian.ai/\n",
            "[jovian] Uploading notebook..\n",
            "[jovian] Capturing environment..\n",
            "[jovian] Committed successfully! https://jovian.ai/ashokdhakad/assignment-1\n",
            "[jovian] Submitting assignment..\n",
            "[jovian] Verify your submission at https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/assignment/assignment-1-all-about-torch-tensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SeQB0S9Huth"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}